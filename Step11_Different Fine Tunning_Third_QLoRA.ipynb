{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a796e53-731c-4ab7-bc2a-76273e41cb04",
   "metadata": {},
   "source": [
    "# Qlora Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16db98-2a03-4942-b970-5be01cbc7db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration \n",
    "MAX_TOKEN_LENGTH = 2048 \n",
    "\n",
    "# Paths\n",
    "input_path = Path(\"/mnt/data/Second Implementation/telequad_v4_reformatted.jsonl\")\n",
    "output_path = Path(f\"/mnt/data/Fifth Implementation/telequad_v4_filtered_semantic_{MAX_TOKEN_LENGTH}.jsonl\")\n",
    "\n",
    "# Load tokenizer and sentence encoder\n",
    "print(\"🔤 Loading tokenizer and sentence encoder...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/mnt/data/llama2-model\")\n",
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"✅ Models loaded.\")\n",
    "\n",
    "# Prompt format\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a precise assistant. Extract the exact answer span from the context. \"\n",
    "    \"Do not paraphrase, summarize, or add extra information. \"\n",
    "    \"The answer must appear exactly in the context.\"\n",
    ")\n",
    "\n",
    "# Semantic Chunking Logic\n",
    "def select_relevant_chunks(context: str, answer: str, window_size=150, stride=100) -> str:\n",
    "    \"\"\"\n",
    "    Sliding window approach to ensure the answer appears in the selected chunk.\n",
    "    \"\"\"\n",
    "    words = context.split()\n",
    "    for start in range(0, len(words), stride):\n",
    "        end = start + window_size\n",
    "        chunk = \" \".join(words[start:end])\n",
    "        if answer in chunk:\n",
    "            return chunk\n",
    "        if end >= len(words):\n",
    "            break\n",
    "    return None\n",
    "\n",
    "# Rebuild prompt from parts\n",
    "def build_prompt(context: str, question: str, answer: str) -> str:\n",
    "    user_prompt = (\n",
    "        f\"Context: {context}\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Answer:\"\n",
    "    )\n",
    "    return f\"<s>[INST] <<SYS>>\\n{SYSTEM_PROMPT}\\n<</SYS>>\\n\\n{user_prompt} [/INST] {answer}</s>\"\n",
    "\n",
    "# Process entries\n",
    "print(\" Processing and filtering entries...\")\n",
    "reformatted_entries = []\n",
    "total_count = 0\n",
    "filtered_out_count = 0\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    num_lines = sum(1 for line in f)\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, total=num_lines, desc=\"Processing file\"):\n",
    "        total_count += 1\n",
    "        try:\n",
    "            entry = json.loads(line)\n",
    "            original_text = entry[\"text\"]\n",
    "\n",
    "            # Parse the original text to extract context, question, and answer\n",
    "            prompt_part, answer = original_text.split(\"[/INST]\", 1)\n",
    "            answer = answer.strip().replace(\"</s>\", \"\")\n",
    "            \n",
    "            # Skip if answer is empty\n",
    "            if not answer:\n",
    "                continue\n",
    "\n",
    "            lines = prompt_part.splitlines()\n",
    "            context_lines, question = [], \"\"\n",
    "            inside_context, inside_question = False, False\n",
    "\n",
    "            for l in lines:\n",
    "                stripped_line = l.strip()\n",
    "                if stripped_line.startswith(\"Context:\"):\n",
    "                    inside_context = True\n",
    "                    inside_question = False\n",
    "                    # Capture text on the same line as \"Context:\"\n",
    "                    context_lines.append(stripped_line.replace(\"Context:\", \"\").strip())\n",
    "                    continue\n",
    "                elif stripped_line.startswith(\"Question:\"):\n",
    "                    inside_question = True\n",
    "                    inside_context = False\n",
    "                    # Capture text on the same line as \"Question:\"\n",
    "                    question = stripped_line.replace(\"Question:\", \"\").strip()\n",
    "                    continue\n",
    "                \n",
    "                if inside_context:\n",
    "                    context_lines.append(l) # Append original line to preserve formatting\n",
    "                elif inside_question and not question:\n",
    "                    question = stripped_line\n",
    "            \n",
    "            full_context = \"\\n\".join(context_lines).strip()\n",
    "\n",
    "            if not full_context or not question:\n",
    "                continue\n",
    "\n",
    "            # Tokenize and decide whether to shorten the context\n",
    "            temp_prompt = build_prompt(full_context, question, answer)\n",
    "            input_ids = tokenizer(temp_prompt)[\"input_ids\"]\n",
    "\n",
    "            final_context = full_context\n",
    "            \n",
    "            # If the full prompt is too long, try to shorten it\n",
    "            if len(input_ids) > MAX_TOKEN_LENGTH:\n",
    "                short_context = select_relevant_chunks(full_context, answer, window_size=150, stride=100)\n",
    "                \n",
    "                if short_context is not None and answer in short_context:\n",
    "                    final_context = short_context\n",
    "                else:\n",
    "                    filtered_out_count += 1\n",
    "                    continue\n",
    "\n",
    "            # Build the final, validated prompt and add it to our list\n",
    "            final_prompt = build_prompt(final_context, question, answer)\n",
    "            reformatted_entries.append({\"text\": final_prompt})\n",
    "\n",
    "        except (ValueError, KeyError) as e:\n",
    "            # Catch potential errors from malformed JSON lines or text splitting.\n",
    "            print(f\"Skipping malformed line {total_count}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Save output\n",
    "print(\" Saving the new dataset...\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for e in reformatted_entries:\n",
    "        f.write(json.dumps(e) + \"\\n\")\n",
    "\n",
    "print(\"\\n--- 📊 Processing Complete ---\")\n",
    "print(f\"Total examples processed: {total_count}\")\n",
    "print(f\"Examples kept for training: {len(reformatted_entries)}\")\n",
    "print(f\"Examples filtered out (answer lost during chunking): {filtered_out_count}\")\n",
    "print(f\"✅ Filtered and reformatted file saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a14d341-fcaa-4ee5-ad17-f45b53faf09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering QA pairs: 4258it [00:45, 94.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered set saved: /mnt/data/Fifth Implementation/telequad_v4_filtered_semantic_2048_semantic_cleaned.jsonl\n",
      "Total kept examples: 576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load Sentence-BERT\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Paths\n",
    "input_path = Path(\"/mnt/data/Fourth Implementation/telequad_v4_filtered_semantic_2048.jsonl\")\n",
    "output_path = Path(\"/mnt/data/Fifth Implementation/telequad_v4_filtered_semantic_2048_semantic_cleaned.jsonl\")\n",
    "\n",
    "# Similarity threshold\n",
    "SIM_THRESHOLD = 0.6\n",
    "\n",
    "def extract_context_and_answer(text):\n",
    "    try:\n",
    "        prompt_part, answer = text.split(\"[/INST]\", 1)\n",
    "        answer = answer.strip().replace(\"</s>\", \"\")\n",
    "        lines = prompt_part.splitlines()\n",
    "\n",
    "        context_lines = []\n",
    "        inside_context = False\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"Context:\"):\n",
    "                inside_context = True\n",
    "                context_lines.append(line.replace(\"Context:\", \"\").strip())\n",
    "                continue\n",
    "            if line.strip().startswith(\"Question:\"):\n",
    "                break\n",
    "            if inside_context:\n",
    "                context_lines.append(line.strip())\n",
    "\n",
    "        context = \" \".join(context_lines)\n",
    "        return context, answer\n",
    "    except:\n",
    "        return \"\", \"\"\n",
    "\n",
    "# Apply filtering\n",
    "kept = []\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"Filtering QA pairs\"):\n",
    "        obj = json.loads(line)\n",
    "        text = obj.get(\"text\", \"\")\n",
    "        context, answer = extract_context_and_answer(text)\n",
    "\n",
    "        if not context or not answer:\n",
    "            continue\n",
    "\n",
    "        context_emb = model.encode(context, convert_to_tensor=True)\n",
    "        answer_emb = model.encode(answer, convert_to_tensor=True)\n",
    "\n",
    "        similarity = util.cos_sim(context_emb, answer_emb).item()\n",
    "        if similarity >= SIM_THRESHOLD:\n",
    "            kept.append(obj)\n",
    "\n",
    "# Save new dataset\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for e in kept:\n",
    "        f.write(json.dumps(e) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Filtered set saved: {output_path}\")\n",
    "print(f\"Total kept examples: {len(kept)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87baf7a8-0caa-4393-9250-77c616c17c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dataset: /mnt/data/Fourth Implementation/telequad_v4_filtered_semantic_2048.jsonl\n",
      "Output dataset: /mnt/data/Fifth Implementation/telequad_v4_golden.jsonl\n",
      "⏳ Reading and cleaning the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 4258/4258 [00:00<00:00, 91736.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving 4258 cleaned entries to the golden dataset...\n",
      "✅ Golden dataset created successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Paths\n",
    "input_path = Path(\"/mnt/data/Fourth Implementation/telequad_v4_filtered_semantic_2048.jsonl\")\n",
    "# The output is our new, clean \"golden\" dataset\n",
    "output_path = Path(\"/mnt/data/Fifth Implementation/telequad_v4_golden.jsonl\")\n",
    "\n",
    "print(f\"Input dataset: {input_path}\")\n",
    "print(f\"Output dataset: {output_path}\")\n",
    "\n",
    "cleaned_entries = []\n",
    "\n",
    "print(\"⏳ Reading and cleaning the dataset...\")\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f.readlines()):\n",
    "        try:\n",
    "            entry = json.loads(line)\n",
    "            text = entry.get(\"text\", \"\")\n",
    "            \n",
    "            # Split the entry into the prompt and the answer\n",
    "            prompt_part, answer_part = text.split(\"[/INST]\", 1)\n",
    "            \n",
    "            # Clean the original answer\n",
    "            original_answer = answer_part.strip().replace(\"</s>\", \"\")\n",
    "            \n",
    "            # The Cleaning Logic\n",
    "            clean_answer = original_answer\n",
    "            \n",
    "            # Rebuild the text entry with the clean answer\n",
    "            new_text = f\"{prompt_part}[/INST] {clean_answer}</s>\"\n",
    "            cleaned_entries.append({\"text\": new_text})\n",
    "\n",
    "        except (ValueError, KeyError) as e:\n",
    "            print(f\"Skipping malformed line: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"💾 Saving {len(cleaned_entries)} cleaned entries to the golden dataset...\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in cleaned_entries:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"✅ Golden dataset created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded2ef21-ebe4-4134-8ae8-5bd47ae11aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer, BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "# Load and Combine Datasets\n",
    "def load_jsonl(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line.strip()) for line in f if line.strip()]\n",
    "\n",
    "v4_path = \"/mnt/data/Fifth Implementation/telequad_v4_golden.jsonl\"\n",
    "\n",
    "v4_data = load_jsonl(v4_path)\n",
    "\n",
    "combined_data = v4_data  \n",
    "dataset = Dataset.from_list(combined_data).shuffle(seed=42)\n",
    "\n",
    "# 90/5/5 Split\n",
    "split = dataset.train_test_split(test_size=0.10, seed=42)\n",
    "val_test = split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "train_dataset = split[\"train\"]\n",
    "val_dataset = val_test[\"train\"]\n",
    "test_dataset = val_test[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1de525f-1e76-4693-9553-d9bdd76abefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔤 Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Load Tokenizer\n",
    "model_path = \"/mnt/data/llama2-model\"  \n",
    "print(\"🔤 Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Padding with eos token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2c238d-926e-46c3-a077-011cd1c37601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2be29148b2f4b71801e771e3cce1623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fc3937c6ff4485a164717557a93f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/213 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize Data\n",
    "def tokenize(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=2048\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, num_proc=4, remove_columns=[\"text\"])\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0518f285-6298-4a97-9e23-b313ecd26c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collator\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=64  # Padding efficiency boost\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160c52a9-a879-446a-a894-eb7b4e650fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Loading LLaMA-2 with LoRA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efac9785f3224d78a055c9fed458b3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 33,554,432 || all params: 6,771,970,048 || trainable%: 0.49548996469513035\n"
     ]
    }
   ],
   "source": [
    "# Load Model with LoRA\n",
    "print(\" Loading LLaMA-2 with LoRA...\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "base_model.gradient_checkpointing_enable()\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d86641-bed4-4224-b64f-cc6f3dbf391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/mnt/data/llama2_qa_lora_output5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e3a9e3-2b77-4b1b-8254-09f9a1791343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Setting up training...\n"
     ]
    }
   ],
   "source": [
    "# Training Arguments\n",
    "print(\"⚙️ Setting up training...\")\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    gradient_accumulation_steps=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=50,\n",
    "    bf16=True,\n",
    "    report_to=\"tensorboard\",\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_num_workers=4,\n",
    "    group_by_length=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    max_grad_norm=1,\n",
    "    warmup_ratio=0.03\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41719dcf-7447-4ec5-8dea-557c708bc923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4534/796332652.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Trainer Setup\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a957ef2c-b05c-4f72-b6e4-2d295c396de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Speed Logging\n",
    "import time\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class SpeedCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.last_time = time.time()\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step % 20 == 0:\n",
    "            now = time.time()\n",
    "            duration = now - self.last_time\n",
    "            print(f\"⚡ Step {state.global_step} — {20/duration:.3f} it/s\")\n",
    "            self.last_time = now\n",
    "\n",
    "trainer.add_callback(SpeedCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3172d2-c0b8-454f-96b0-0c09ed454bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='960' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [960/960 7:15:49, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.563500</td>\n",
       "      <td>1.540274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.510600</td>\n",
       "      <td>1.478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.437800</td>\n",
       "      <td>1.437512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.388900</td>\n",
       "      <td>1.415154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.362300</td>\n",
       "      <td>1.403938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.387000</td>\n",
       "      <td>1.402174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Step 20 — 0.026 it/s\n",
      "⚡ Step 40 — 0.055 it/s\n",
      "⚡ Step 60 — 0.028 it/s\n",
      "⚡ Step 80 — 0.049 it/s\n",
      "⚡ Step 100 — 0.031 it/s\n",
      "⚡ Step 120 — 0.044 it/s\n",
      "⚡ Step 140 — 0.032 it/s\n",
      "⚡ Step 160 — 0.061 it/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/data/llama2-model - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Step 180 — 0.024 it/s\n",
      "⚡ Step 200 — 0.055 it/s\n",
      "⚡ Step 220 — 0.028 it/s\n",
      "⚡ Step 240 — 0.048 it/s\n",
      "⚡ Step 260 — 0.029 it/s\n",
      "⚡ Step 280 — 0.045 it/s\n",
      "⚡ Step 300 — 0.035 it/s\n",
      "⚡ Step 320 — 0.062 it/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/data/llama2-model - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Step 340 — 0.024 it/s\n",
      "⚡ Step 360 — 0.055 it/s\n",
      "⚡ Step 380 — 0.028 it/s\n",
      "⚡ Step 400 — 0.049 it/s\n",
      "⚡ Step 420 — 0.031 it/s\n",
      "⚡ Step 440 — 0.045 it/s\n",
      "⚡ Step 460 — 0.032 it/s\n",
      "⚡ Step 480 — 0.060 it/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/data/llama2-model - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Step 500 — 0.024 it/s\n",
      "⚡ Step 520 — 0.055 it/s\n",
      "⚡ Step 540 — 0.028 it/s\n",
      "⚡ Step 560 — 0.048 it/s\n",
      "⚡ Step 580 — 0.031 it/s\n",
      "⚡ Step 600 — 0.045 it/s\n",
      "⚡ Step 620 — 0.033 it/s\n",
      "⚡ Step 640 — 0.059 it/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/data/llama2-model - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Step 660 — 0.024 it/s\n",
      "⚡ Step 680 — 0.055 it/s\n",
      "⚡ Step 700 — 0.028 it/s\n",
      "⚡ Step 720 — 0.048 it/s\n",
      "⚡ Step 740 — 0.030 it/s\n",
      "⚡ Step 760 — 0.044 it/s\n",
      "⚡ Step 780 — 0.033 it/s\n",
      "⚡ Step 800 — 0.062 it/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/data/llama2-model - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Step 820 — 0.024 it/s\n",
      "⚡ Step 840 — 0.055 it/s\n",
      "⚡ Step 860 — 0.028 it/s\n",
      "⚡ Step 880 — 0.049 it/s\n",
      "⚡ Step 900 — 0.030 it/s\n",
      "⚡ Step 920 — 0.044 it/s\n",
      "⚡ Step 940 — 0.033 it/s\n",
      "⚡ Step 960 — 0.060 it/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/data/llama2-model - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=960, training_loss=1.4937201897303263, metrics={'train_runtime': 26224.2692, 'train_samples_per_second': 0.877, 'train_steps_per_second': 0.037, 'total_flos': 6.761883522453996e+17, 'train_loss': 1.4937201897303263, 'epoch': 6.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Training\n",
    "print(\"🚀 Starting fine-tuning...\")\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d05bff8-1f65-4aab-bd7c-982f41f28da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(trainer.state.log_history)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"/mnt/data/Fifth Implementation/loss_history1.csv\", index=False)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(df[\"step\"], df[\"loss\"], label=\"Training Loss\", marker='o')\n",
    "plt.plot(df[\"step\"], df[\"eval_loss\"], label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "694354c9-42a6-4462-8ffd-032d8925f857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/data/llama2-model - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/mnt/data/llama2_qa_lora_output5/final/tokenizer_config.json',\n",
       " '/mnt/data/llama2_qa_lora_output5/final/special_tokens_map.json',\n",
       " '/mnt/data/llama2_qa_lora_output5/final/tokenizer.model',\n",
       " '/mnt/data/llama2_qa_lora_output5/final/added_tokens.json',\n",
       " '/mnt/data/llama2_qa_lora_output5/final/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Final Model\n",
    "print(\"💾 Saving model...\")\n",
    "trainer.save_model(f\"{output_dir}/final\")\n",
    "tokenizer.save_pretrained(f\"{output_dir}/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "483c15c6-b580-4908-8a4d-14da39267980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prediction(raw_text):\n",
    "    answer = raw_text.split(\"[/INST]\")[-1].strip()\n",
    "    answer = re.sub(r\"[^\\w\\s\\-.,:/()]\", \"\", answer)\n",
    "\n",
    "    # Clip to first sentence-ending punctuation\n",
    "    sentence_end = re.search(r'[.?!]', answer)\n",
    "    if sentence_end:\n",
    "        answer = answer[:sentence_end.end()]\n",
    "\n",
    "    return answer.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c9bf5e1-73f7-4196-88df-849360cee595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Loading fine-tuned model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50debd3ebec34263baee9a0b984e68f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Processing test set...\n",
      "🔮 Generating predictions with aggressive post-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/54 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "  2%|▊                                           | 1/54 [00:06<05:30,  6.23s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "  4%|█▋                                          | 2/54 [00:13<05:59,  6.91s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "  6%|██▍                                         | 3/54 [00:20<05:48,  6.84s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "  7%|███▎                                        | 4/54 [00:27<05:52,  7.05s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "  9%|████                                        | 5/54 [00:33<05:28,  6.71s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 11%|████▉                                       | 6/54 [00:40<05:28,  6.85s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 13%|█████▋                                      | 7/54 [00:48<05:29,  7.01s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 15%|██████▌                                     | 8/54 [00:54<05:07,  6.69s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 17%|███████▎                                    | 9/54 [00:59<04:43,  6.30s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 19%|███████▉                                   | 10/54 [01:05<04:28,  6.10s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 20%|████████▊                                  | 11/54 [01:09<03:57,  5.53s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 22%|█████████▌                                 | 12/54 [01:16<04:03,  5.80s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 24%|██████████▎                                | 13/54 [01:22<04:09,  6.08s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 26%|███████████▏                               | 14/54 [01:28<03:52,  5.82s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 28%|███████████▉                               | 15/54 [01:32<03:34,  5.51s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 30%|████████████▋                              | 16/54 [01:40<03:51,  6.09s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 31%|█████████████▌                             | 17/54 [01:45<03:38,  5.90s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 33%|██████████████▎                            | 18/54 [01:53<03:49,  6.38s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 35%|███████████████▏                           | 19/54 [01:59<03:47,  6.49s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 37%|███████████████▉                           | 20/54 [02:06<03:40,  6.48s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 39%|████████████████▋                          | 21/54 [02:10<03:11,  5.80s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 41%|█████████████████▌                         | 22/54 [02:17<03:12,  6.02s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 43%|██████████████████▎                        | 23/54 [02:22<03:03,  5.93s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 44%|███████████████████                        | 24/54 [02:29<03:08,  6.29s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 46%|███████████████████▉                       | 25/54 [02:36<03:04,  6.35s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 48%|████████████████████▋                      | 26/54 [02:43<03:06,  6.68s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 50%|█████████████████████▌                     | 27/54 [02:50<03:03,  6.78s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 52%|██████████████████████▎                    | 28/54 [02:54<02:28,  5.72s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 54%|███████████████████████                    | 29/54 [03:01<02:35,  6.23s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 56%|███████████████████████▉                   | 30/54 [03:07<02:23,  5.98s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 57%|████████████████████████▋                  | 31/54 [03:10<02:02,  5.33s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 59%|█████████████████████████▍                 | 32/54 [03:18<02:11,  5.99s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 61%|██████████████████████████▎                | 33/54 [03:25<02:13,  6.34s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 63%|███████████████████████████                | 34/54 [03:30<02:01,  6.07s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 65%|███████████████████████████▊               | 35/54 [03:36<01:53,  5.96s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 67%|████████████████████████████▋              | 36/54 [03:42<01:46,  5.94s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 69%|█████████████████████████████▍             | 37/54 [03:47<01:34,  5.55s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 70%|██████████████████████████████▎            | 38/54 [03:53<01:30,  5.68s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 72%|███████████████████████████████            | 39/54 [03:59<01:29,  5.97s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 74%|███████████████████████████████▊           | 40/54 [04:07<01:28,  6.34s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 76%|████████████████████████████████▋          | 41/54 [04:12<01:17,  6.00s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 78%|█████████████████████████████████▍         | 42/54 [04:19<01:17,  6.45s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 80%|██████████████████████████████████▏        | 43/54 [04:26<01:12,  6.61s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 81%|███████████████████████████████████        | 44/54 [04:33<01:05,  6.58s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 83%|███████████████████████████████████▊       | 45/54 [04:37<00:52,  5.83s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 85%|████████████████████████████████████▋      | 46/54 [04:42<00:44,  5.62s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 87%|█████████████████████████████████████▍     | 47/54 [04:48<00:41,  5.87s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 89%|██████████████████████████████████████▏    | 48/54 [04:52<00:31,  5.33s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 91%|███████████████████████████████████████    | 49/54 [05:00<00:29,  5.95s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 93%|███████████████████████████████████████▊   | 50/54 [05:07<00:24,  6.23s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 94%|████████████████████████████████████████▌  | 51/54 [05:10<00:16,  5.49s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 96%|█████████████████████████████████████████▍ | 52/54 [05:15<00:10,  5.34s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 98%|██████████████████████████████████████████▏| 53/54 [05:22<00:05,  5.71s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "100%|███████████████████████████████████████████| 54/54 [05:24<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Calculating metrics...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2313cf7ad1e14d70be8636cb765b1c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2709f27a14e347799d9caffcb14eefa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟩 ROUGE-L: 0.59\n",
      "🟦 BLEU: 0.38\n",
      "\n",
      "✅ Exact Match (EM): 28.17\n",
      "📈 F1 Score: 58.82\n",
      "✅ Detailed test set results saved to: /mnt/data/Fifth Implementation/test_dataset_eval_results_FINAL.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, StoppingCriteria, StoppingCriteriaList\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Reload model and tokenizer\n",
    "model_path = \"/mnt/data/llama2_qa_lora_output5/final\" \n",
    "print(\" Loading fine-tuned model and tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Define a custom stopping criteria\n",
    "class StopOnNewline(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        return input_ids[0, -1] == 13 # Token ID for newline\n",
    "\n",
    "# Create the pipeline\n",
    "qa_pipeline = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Load the test dataset\n",
    "\n",
    "def extract_prompt_and_answer(entry):\n",
    "    try:\n",
    "        text = entry[\"text\"]\n",
    "        parts = text.split(\"[/INST]\")\n",
    "        prompt = parts[0] + \"[/INST]\"\n",
    "        reference = parts[1].strip().replace(\"</s>\", \"\")\n",
    "        return {\"prompt\": prompt, \"reference\": reference}\n",
    "    except Exception:\n",
    "        return {\"prompt\": \"\", \"reference\": \"\"}\n",
    "\n",
    "print(\"📝 Processing test set...\")\n",
    "processed = [extract_prompt_and_answer(ex) for ex in test_dataset]\n",
    "processed = [ex for ex in processed if ex[\"prompt\"].strip() and ex[\"reference\"].strip()]\n",
    "\n",
    "# Inference\n",
    "print(\" Generating predictions with aggressive post-processing...\")\n",
    "predictions = []\n",
    "batch_size = 4\n",
    "\n",
    "for i in tqdm(range(0, len(processed), batch_size)):\n",
    "    batch_prompts = [ex[\"prompt\"] for ex in processed[i:i + batch_size]]\n",
    "    \n",
    "    batch_outputs = qa_pipeline(\n",
    "        batch_prompts, \n",
    "        max_new_tokens=40,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.encode(\"</s>\")[0],\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    for out in batch_outputs:\n",
    "        gen_text = out[0][\"generated_text\"]\n",
    "        cleaned_answer = clean_prediction(gen_text)\n",
    "        predictions.append(cleaned_answer)\n",
    "# Evaluation using SQuAD metric\n",
    "print(\"📊 Calculating metrics...\")\n",
    "references = [ex[\"reference\"] for ex in processed]\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "\n",
    "formatted_preds = [{\"id\": str(i), \"prediction_text\": p} for i, p in enumerate(predictions)]\n",
    "formatted_refs = [{\"id\": str(i), \"answers\": {\"text\": [r], \"answer_start\": [0]}} for i, r in enumerate(references)]\n",
    "\n",
    "results = squad_metric.compute(predictions=formatted_preds, references=formatted_refs)\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bleu_result = bleu.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(f\"🟩 ROUGE-L: {rouge_result['rougeL']:.2f}\")\n",
    "print(f\"🟦 BLEU: {bleu_result['bleu']:.2f}\")\n",
    "print(f\"\\n✅ Exact Match (EM): {results['exact_match']:.2f}\")\n",
    "print(f\"📈 F1 Score: {results['f1']:.2f}\")\n",
    "\n",
    "# --- Save Detailed CSV ---\n",
    "df = pd.DataFrame({\n",
    "    \"id\": list(range(len(predictions))),\n",
    "    \"prompt\": [ex[\"prompt\"] for ex in processed],\n",
    "    \"reference\": references,\n",
    "    \"prediction\": predictions\n",
    "})\n",
    "df[\"exact_match\"] = [squad_metric.compute(predictions=[formatted_preds[i]], references=[formatted_refs[i]])[\"exact_match\"] for i in range(len(predictions))]\n",
    "df[\"f1\"] = [squad_metric.compute(predictions=[formatted_preds[i]], references=[formatted_refs[i]])[\"f1\"] for i in range(len(predictions))]\n",
    "csv_path = \"/mnt/data/Fifth Implementation/test_dataset_eval_results_FINAL.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"✅ Detailed test set results saved to: {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
